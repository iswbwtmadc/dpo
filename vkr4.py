# -*- coding: utf-8 -*-
"""vkr4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R4hEOMBVFe9dhS2N3mNitxGqSGF2EHSp
"""

import requests
!pip install selenium
import selenium
import soupsieve
from bs4 import BeautifulSoup

!pip install langchain[all]

page1 = requests.get('https://www.hse.ru/edu/dpo/?onlyActual=0')
soup2=BeautifulSoup(page1.text,'html.parser')
urls2 = []
alltags=soup2.select("a[href*='hse.ru/edu/dpo']")
for item in alltags:
    if len(item['href']) < 40:
        urls2.append((item['href']))

for i in range(2, 40):
    link = 'https://www.hse.ru/edu/dpo/?page=' + str(i) + '&onlyActual=0'
    page = requests.get(link)
    soup2=BeautifulSoup(page.text,'html.parser')
    alltags=soup2.select("a[href*='hse.ru/edu/dpo']")
    for item in alltags:
        if len(item['href']) < 42 and item['href'] not in urls2:
            urls2.append((item['href']))
#print(len(urls2))

from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader(urls2)
docs = loader.load()

from langchain.text_splitter import RecursiveCharacterTextSplitter
r_splitter = RecursiveCharacterTextSplitter(separators = ["Программа обучения", "Формат обучения", "График обучения", "Стоимость и условия", "nn", "n", " "])

splits = r_splitter.split_documents(docs)

!pip install sentence-transformers
from sentence_transformers import SentenceTransformer

from langchain.embeddings import SentenceTransformerEmbeddings
embedding_function = SentenceTransformerEmbeddings(model_name='ai-forever/ruT5-large')
#embedding_function2 = SentenceTransformerEmbeddings(model_name='ai-forever/rugpt3large_based_on_gpt2')
embedding_function3 = SentenceTransformerEmbeddings(model_name='intfloat/multilingual-e5-large')

import getpass
import os

!pip install qdrant-client

from langchain_community.vectorstores import Qdrant

#!pip uninstall -y python3-protobuf
#!pip uninstall -y protobuf

#!pip install protobuf

#!pip install qdrant-client

#!pip install --upgrade pip

url = "https://88c128b7-6432-4bcf-aa91-27bb78990c30.us-east4-0.gcp.cloud.qdrant.io"
api_key = "B4jBqmIUhizGuWaHWX8JkIy2wt_Wsg2UMt3nU-DFp1kUMKJD-tw4hw"
qdrant = Qdrant.from_documents(
    splits,
    embedding_function,
    url=url,
    prefer_grpc=True,
    api_key=api_key,
    collection_name="vkr3",
    force_recreate=True
)

query = "анализ данных"

ans1 = qdrant.similarity_search(query)
print(ans1[0])

from qdrant_client import QdrantClient

qdrant_client = QdrantClient(
    url="https://88c128b7-6432-4bcf-aa91-27bb78990c30.us-east4-0.gcp.cloud.qdrant.io:6333",
    api_key="B4jBqmIUhizGuWaHWX8JkIy2wt_Wsg2UMt3nU-DFp1kUMKJD-tw4hw",
)

doc_store = Qdrant(
    client=qdrant_client, collection_name="vkr2",
    embeddings=embedding_function3,
)

query = "Цифровая иллюстрация: Создание цифровых иллюстраций с помощью Procreate или Adobe Photoshop"

ans1 = doc_store.similarity_search(query, 2)
#print(ans1)
for doc in ans1:
  print(doc)